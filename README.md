# DR.Experts: Differential Refinement of Distortion-Aware Experts for Blind Image Quality Assessment

This repository contains the official implementation of our AAAI 2026 paper:

&gt;  Author: Bohan Fu, Guanyi Qin, Fazhan Zhang, Zihao Huang, Mingxuan Li, Runze Hu1  
&gt; *AAAI Conference on Artificial Intelligence (AAAI), 2026*
---

## ðŸ“– Abstract

Blind Image Quality Assessment, aiming to replicate human perception of visual quality without reference, plays a key role in vision tasks, yet existing models often fail to effectively capture subtle distortion cues, leading to a misalignment with human subjective judgments. We identify that the root cause of this limitation lies in the lack of reliable distortion priors, as methods typically learn shallow relationships between unified image features and quality scores, resulting in their insensitive nature to distortions and thus limiting their performance. To address this, we introduce DR.Experts, a novel prior-driven BIQA framework designed to explicitly incorporate distortion priors, enabling a reliable quality assessment. DR.Experts begins by leveraging a degradation-aware vision-language model to obtain distortion-specific priors, which are further refined and enhanced by the proposed Distortion-Saliency Differential Module through distinguishing them from semantic attentions, thereby ensuring the genuine representations of distortions. The refined priors, along with semantics and bridging representation, 
are then fused by a proposed mixture-of-experts style module named the Dynamic Distortion Weighting Module. 
This mechanism  weights each distortion-specific feature as per its perceptual impact, ensuring that the final quality prediction aligns with human perception. 
Extensive experiments conducted on five challenging BIQA benchmarks demonstrate the superiority of DR.Experts over current methods and showcase its excellence in terms of generalization 
and data efficiency. 

---

